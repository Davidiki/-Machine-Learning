{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Modelos Lineares**\n",
        "Os modelos lineares s√£o uma classe fundamental de algoritmos de aprendizado de m√°quina utilizados tanto para tarefas de regress√£o quanto de classifica√ß√£o. Eles se baseiam na premissa de que a rela√ß√£o entre as vari√°veis independentes `(features)` e a vari√°vel dependente `(target)` pode ser aproximada por uma combina√ß√£o linear das features.\n",
        "\n",
        "##**Caracter√≠sticas dos Modelos Lineares**\n",
        "\n",
        "- **Simplicidade:** F√°ceis de entender e implementar.\n",
        "- **Interpretabilidade:** Coeficientes que indicam a import√¢ncia e a dire√ß√£o do impacto de cada feature.\n",
        "- **Efici√™ncia Computacional:** R√°pidos para treinar, mesmo com grandes conjuntos de dados.\n",
        "- **Requisitos de Dados:** Funcionam melhor quando h√° uma rela√ß√£o linear entre as features e o target.\n",
        "\n",
        "No entanto, os modelos lineares tamb√©m possuem limita√ß√µes, como a incapacidade de capturar rela√ß√µes n√£o lineares complexas e a sensibilidade a outliers."
      ],
      "metadata": {
        "id": "nm-ME7CLqlNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas necess√°rias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, Lasso, Ridge, ElasticNet\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "O1CmJDkUp2dp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Carregando o dataset breast_cancer\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)"
      ],
      "metadata": {
        "id": "qpXiXl16p5Jw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo o dataset em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "TsT4VNeQp8Fm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Regress√£o Log√≠stica**\n",
        "**Funcionamento:** A Regress√£o Log√≠stica √© utilizada para problemas de classifica√ß√£o bin√°ria. Diferentemente da regress√£o linear, que prev√™ valores cont√≠nuos, a regress√£o log√≠stica estima a probabilidade de uma amostra pertencer a uma classe espec√≠fica usando a fun√ß√£o sigmoide:\n",
        "\n",
        "ùëÉ\n",
        "(\n",
        "ùë¶\n",
        "=\n",
        "1\n",
        "‚à£\n",
        "ùëã\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ùëí\n",
        "‚àí\n",
        "(\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùëã\n",
        "1\n",
        "+\n",
        "‚ãØ\n",
        "+\n",
        "ùõΩ\n",
        "ùëõ\n",
        "ùëã\n",
        "ùëõ\n",
        ")\n",
        "P(y=1‚à£X)=\n",
        "1+e\n",
        "‚àí(Œ≤\n",
        "0\n",
        "‚Äã\n",
        " +Œ≤\n",
        "1\n",
        "‚Äã\n",
        " X\n",
        "1\n",
        "‚Äã\n",
        " +‚ãØ+Œ≤\n",
        "n\n",
        "‚Äã\n",
        " X\n",
        "n\n",
        "‚Äã\n",
        " )\n",
        "\n",
        "1\n",
        "‚Äã\n",
        "\n",
        "O modelo ajusta os coeficientes\n",
        "ùõΩ\n",
        "Œ≤ para maximizar a verossimilhan√ßa dos dados observados.\n",
        "\n",
        "**Pontos Fortes:**\n",
        "- Interpreta√ß√£o Simples: Coeficientes indicam a dire√ß√£o e a magnitude do impacto das features.\n",
        "- Probabilidades de Sa√≠da: Fornece probabilidades, permitindo uma avalia√ß√£o mais granular.\n",
        "- Eficiente Computacionalmente: R√°pido para treinar em grandes conjuntos de dados.\n",
        "\n",
        "**Pontos Fracos**\n",
        "- Linearidade: Assume uma rela√ß√£o linear entre as features e o logit da probabilidade.\n",
        "- Sens√≠vel a Outliers: Valores at√≠picos podem influenciar significativamente o modelo.\n",
        "- Multicolinearidade: Pode ser afetada por alta correla√ß√£o entre as features."
      ],
      "metadata": {
        "id": "rmoI8nQcrK0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Regress√£o Log√≠stica\n",
        "log_reg = LogisticRegression(max_iter=10000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "print(\"Regress√£o Log√≠stica\")\n",
        "print(\"Acur√°cia:\", accuracy_score(y_test, y_pred_log_reg))\n",
        "print(classification_report(y_test, y_pred_log_reg))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvNz6L8Lp_bF",
        "outputId": "49e20097-f852-48c4-f571-29c1d96c73b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regress√£o Log√≠stica\n",
            "Acur√°cia: 0.9766081871345029\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        63\n",
            "           1       0.98      0.98      0.98       108\n",
            "\n",
            "    accuracy                           0.98       171\n",
            "   macro avg       0.97      0.97      0.97       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Lasso Regression (Regress√£o Lasso)**\n",
        "**Funcionamento**\n",
        "A Regress√£o Lasso √© uma variante da regress√£o linear que incorpora regulariza√ß√£o L1. O objetivo √© minimizar a soma dos erros quadr√°ticos com uma penaliza√ß√£o proporcional √† soma dos valores absolutos dos coeficientes:\n",
        "\n",
        "min\n",
        "‚Å°\n",
        "(\n",
        "‚àë\n",
        "ùëñ\n",
        "=\n",
        "1\n",
        "ùëö\n",
        "(\n",
        "ùë¶\n",
        "ùëñ\n",
        "‚àí\n",
        "ùõΩ\n",
        "0\n",
        "‚àí\n",
        "‚àë\n",
        "ùëó\n",
        "=\n",
        "1\n",
        "ùëõ\n",
        "ùõΩ\n",
        "ùëó\n",
        "ùëã\n",
        "ùëñ\n",
        "ùëó\n",
        ")\n",
        "2\n",
        "+\n",
        "ùúÜ\n",
        "‚àë\n",
        "ùëó\n",
        "=\n",
        "1\n",
        "ùëõ\n",
        "‚à£\n",
        "ùõΩ\n",
        "ùëó\n",
        "‚à£\n",
        ")\n",
        "min(\n",
        "i=1\n",
        "‚àë\n",
        "m\n",
        "‚Äã\n",
        " (y\n",
        "i\n",
        "‚Äã\n",
        " ‚àíŒ≤\n",
        "0\n",
        "‚Äã\n",
        " ‚àí\n",
        "j=1\n",
        "‚àë\n",
        "n\n",
        "‚Äã\n",
        " Œ≤\n",
        "j\n",
        "‚Äã\n",
        " X\n",
        "ij\n",
        "‚Äã\n",
        " )\n",
        "2\n",
        " +Œª\n",
        "j=1\n",
        "‚àë\n",
        "n\n",
        "‚Äã\n",
        " ‚à£Œ≤\n",
        "j\n",
        "‚Äã\n",
        " ‚à£)\n",
        "\n",
        "Essa penaliza√ß√£o for√ßa alguns coeficientes a serem exatamente zero, realizando sele√ß√£o de features.\n",
        "\n",
        "**Pontos Fortes**\n",
        "- Sele√ß√£o de Features: Reduz a complexidade do modelo eliminando features irrelevantes.\n",
        "- Preven√ß√£o de Overfitting: A regulariza√ß√£o ajuda a evitar sobreajuste aos dados de treinamento.\n",
        "- Interpreta√ß√£o Simplificada: Modelos mais simples s√£o mais f√°ceis de interpretar.\n",
        "\n",
        "**Pontos Fracos**\n",
        "- Pode Excluir Features √öteis: Em alguns casos, pode remover features que s√£o relevantes.\n",
        "- Sens√≠vel ao Par√¢metro\n",
        "ùúÜ\n",
        "Œª: A escolha inadequada de\n",
        "ùúÜ\n",
        "Œª pode prejudicar o desempenho.\n",
        "- N√£o Lida Bem com Multicolinearidade: Pode selecionar arbitrariamente uma entre v√°rias features correlacionadas."
      ],
      "metadata": {
        "id": "Ol1pH0wWrn41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Lasso Regression\n",
        "lasso_reg = Lasso(alpha=0.01)\n",
        "lasso_reg.fit(X_train, y_train)\n",
        "y_pred_lasso = lasso_reg.predict(X_test)\n",
        "y_pred_lasso_class = [1 if i >= 0.5 else 0 for i in y_pred_lasso]\n",
        "print(\"\\nLasso Regression\")\n",
        "print(\"Acur√°cia:\", accuracy_score(y_test, y_pred_lasso_class))\n",
        "print(classification_report(y_test, y_pred_lasso_class))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbV-uBIkqBQu",
        "outputId": "52610b4e-db52-4e3a-a164-2033cdd8f82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lasso Regression\n",
            "Acur√°cia: 0.9649122807017544\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.92      0.95        63\n",
            "           1       0.96      0.99      0.97       108\n",
            "\n",
            "    accuracy                           0.96       171\n",
            "   macro avg       0.97      0.96      0.96       171\n",
            "weighted avg       0.97      0.96      0.96       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ridge Regression (Regress√£o Ridge)**\n",
        "**Funcionamento**\n",
        "A Regress√£o Ridge √© outra variante da regress√£o linear que utiliza regulariza√ß√£o L2. O objetivo √© minimizar a soma dos erros quadr√°ticos com uma penaliza√ß√£o proporcional √† soma dos quadrados dos coeficientes:\n",
        "\n",
        "min\n",
        "‚Å°\n",
        "(\n",
        "‚àë\n",
        "ùëñ\n",
        "=\n",
        "1\n",
        "ùëö\n",
        "(\n",
        "ùë¶\n",
        "ùëñ\n",
        "‚àí\n",
        "ùõΩ\n",
        "0\n",
        "‚àí\n",
        "‚àë\n",
        "ùëó\n",
        "=\n",
        "1\n",
        "ùëõ\n",
        "ùõΩ\n",
        "ùëó\n",
        "ùëã\n",
        "ùëñ\n",
        "ùëó\n",
        ")\n",
        "2\n",
        "+\n",
        "ùúÜ\n",
        "‚àë\n",
        "ùëó\n",
        "=\n",
        "1\n",
        "ùëõ\n",
        "ùõΩ\n",
        "ùëó\n",
        "2\n",
        ")\n",
        "min(\n",
        "i=1\n",
        "‚àë\n",
        "m\n",
        "‚Äã\n",
        " (y\n",
        "i\n",
        "‚Äã\n",
        " ‚àíŒ≤\n",
        "0\n",
        "‚Äã\n",
        " ‚àí\n",
        "j=1\n",
        "‚àë\n",
        "n\n",
        "‚Äã\n",
        " Œ≤\n",
        "j\n",
        "‚Äã\n",
        " X\n",
        "ij\n",
        "‚Äã\n",
        " )\n",
        "2\n",
        " +Œª\n",
        "j=1\n",
        "‚àë\n",
        "n\n",
        "‚Äã\n",
        " Œ≤\n",
        "j\n",
        "2\n",
        "‚Äã\n",
        " )\n",
        "Diferente da Lasso, a Ridge n√£o for√ßa os coeficientes a zero, mas os mant√©m pequenos.\n",
        "\n",
        "**Pontos Fortes**\n",
        "- Gerencia Multicolinearidade: Reduz a vari√¢ncia dos coeficientes em presen√ßa de alta correla√ß√£o entre as features.\n",
        "- Estabilidade: Produz coeficientes mais est√°veis e menos sens√≠veis a pequenas varia√ß√µes nos dados.\n",
        "- Preven√ß√£o de Overfitting: A regulariza√ß√£o L2 ajuda a evitar sobreajuste.\n",
        "\n",
        "**Pontos Fracos**\n",
        "- N√£o Realiza Sele√ß√£o de Features: Mant√©m todas as features no modelo, mesmo as menos relevantes.\n",
        "- Interpreta√ß√£o dos Coeficientes: Coeficientes regularizados s√£o mais dif√≠ceis de interpretar diretamente.\n",
        "- Depend√™ncia do Par√¢metro\n",
        "ùúÜ\n",
        "Œª: A escolha de\n",
        "ùúÜ\n",
        "Œª afeta significativamente o desempenho do modelo."
      ],
      "metadata": {
        "id": "mIjZPXjdr-cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Ridge Regression\n",
        "ridge_reg = Ridge(alpha=1.0)\n",
        "ridge_reg.fit(X_train, y_train)\n",
        "y_pred_ridge = ridge_reg.predict(X_test)\n",
        "y_pred_ridge_class = [1 if i >= 0.5 else 0 for i in y_pred_ridge]\n",
        "print(\"\\nRidge Regression\")\n",
        "print(\"Acur√°cia:\", accuracy_score(y_test, y_pred_ridge_class))\n",
        "print(classification_report(y_test, y_pred_ridge_class))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzMxc_z1qEyl",
        "outputId": "73a703d2-e367-46ad-c33d-edb093bc13af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ridge Regression\n",
            "Acur√°cia: 0.9649122807017544\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.95        63\n",
            "           1       0.96      0.98      0.97       108\n",
            "\n",
            "    accuracy                           0.96       171\n",
            "   macro avg       0.97      0.96      0.96       171\n",
            "weighted avg       0.96      0.96      0.96       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Elastic Net**\n",
        "**Funcionamento**\n",
        "O Elastic Net combina as regulariza√ß√µes L1 e L2, incorporando ambas no objetivo de minimiza√ß√£o:\n",
        "\n",
        "min\n",
        "‚Å°\n",
        "(\n",
        "‚àë\n",
        "ùëñ\n",
        "=\n",
        "1\n",
        "ùëö\n",
        "(\n",
        "ùë¶\n",
        "ùëñ\n",
        "‚àí\n",
        "ùõΩ\n",
        "0\n",
        "‚àí\n",
        "‚àë\n",
        "ùëó\n",
        "=\n",
        "1\n",
        "ùëõ\n",
        "ùõΩ\n",
        "ùëó\n",
        "ùëã\n",
        "ùëñ\n",
        "ùëó\n",
        ")\n",
        "2\n",
        "+\n",
        "ùúÜ\n",
        "1\n",
        "‚àë\n",
        "ùëó\n",
        "=\n",
        "1\n",
        "ùëõ\n",
        "‚à£\n",
        "ùõΩ\n",
        "ùëó\n",
        "‚à£\n",
        "+\n",
        "ùúÜ\n",
        "2\n",
        "‚àë\n",
        "ùëó\n",
        "=\n",
        "1\n",
        "ùëõ\n",
        "ùõΩ\n",
        "ùëó\n",
        "2\n",
        ")\n",
        "min(\n",
        "i=1\n",
        "‚àë\n",
        "m\n",
        "‚Äã\n",
        " (y\n",
        "i\n",
        "‚Äã\n",
        " ‚àíŒ≤\n",
        "0\n",
        "‚Äã\n",
        " ‚àí\n",
        "j=1\n",
        "‚àë\n",
        "n\n",
        "‚Äã\n",
        " Œ≤\n",
        "j\n",
        "‚Äã\n",
        " X\n",
        "ij\n",
        "‚Äã\n",
        " )\n",
        "2\n",
        " +Œª\n",
        "1\n",
        "‚Äã\n",
        "  \n",
        "j=1\n",
        "‚àë\n",
        "n\n",
        "‚Äã\n",
        " ‚à£Œ≤\n",
        "j\n",
        "‚Äã\n",
        " ‚à£+Œª\n",
        "2\n",
        "‚Äã\n",
        "  \n",
        "j=1\n",
        "‚àë\n",
        "n\n",
        "‚Äã\n",
        " Œ≤\n",
        "j\n",
        "2\n",
        "‚Äã\n",
        " )\n",
        "Isso permite tanto a sele√ß√£o de features quanto a redu√ß√£o da vari√¢ncia dos coeficientes.\n",
        "\n",
        "**Pontos Fortes**\n",
        "- Combina√ß√£o de Lasso e Ridge: Herda os benef√≠cios de ambos os m√©todos.\n",
        "- Sele√ß√£o de Features e Regulariza√ß√£o: Pode selecionar features relevantes enquanto mant√©m os coeficientes pequenos.\n",
        "- Flexibilidade: Ajusta a propor√ß√£o entre L1 e L2 conforme necess√°rio.\n",
        "\n",
        "**Pontos Fracos**\n",
        "- Complexidade Adicional: Mais par√¢metros para ajustar (pesos de L1 e L2).\n",
        "- Interpreta√ß√£o dos Coeficientes: A combina√ß√£o de L1 e L2 pode complicar a interpreta√ß√£o direta.\n",
        "- Requer Ajuste Cuidadoso dos Par√¢metros: O desempenho depende da escolha adequada dos hiperpar√¢metros."
      ],
      "metadata": {
        "id": "pq2cZsl0sW8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elastic Net\n",
        "elastic_net = ElasticNet(alpha=0.01, l1_ratio=0.5)\n",
        "elastic_net.fit(X_train, y_train)\n",
        "y_pred_elastic = elastic_net.predict(X_test)\n",
        "y_pred_elastic_class = [1 if i >= 0.5 else 0 for i in y_pred_elastic]\n",
        "print(\"\\nElastic Net\")\n",
        "print(\"Acur√°cia:\", accuracy_score(y_test, y_pred_elastic_class))\n",
        "print(classification_report(y_test, y_pred_elastic_class))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjhx7iqWqF_e",
        "outputId": "840cfd25-9e50-4901-b660-1049b5e09402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Elastic Net\n",
            "Acur√°cia: 0.9649122807017544\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.92      0.95        63\n",
            "           1       0.96      0.99      0.97       108\n",
            "\n",
            "    accuracy                           0.96       171\n",
            "   macro avg       0.97      0.96      0.96       171\n",
            "weighted avg       0.97      0.96      0.96       171\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+00, tolerance: 9.322e-03\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **An√°lise Discriminante Linear (LDA)**\n",
        "\n",
        "**Funcionamento**\n",
        "A An√°lise Discriminante Linear (LDA) √© um m√©todo estat√≠stico usado para encontrar uma combina√ß√£o linear de features que melhor separa duas ou mais classes. Assume que as diferentes classes compartilham a mesma matriz de covari√¢ncia e que as distribui√ß√µes das classes s√£o gaussianas.\n",
        "\n",
        "O LDA busca maximizar a separa√ß√£o entre as m√©dias das classes enquanto minimiza a vari√¢ncia dentro das classes, resultando em uma ou mais dire√ß√µes discriminantes.\n",
        "\n",
        "**Pontos Fortes**\n",
        "- Efici√™ncia Computacional: R√°pido para treinar e prever.\n",
        "- Interpreta√ß√£o Intuitiva: Proje√ß√£o das features em um espa√ßo de menor dimens√£o.\n",
        "- Bom Desempenho com Poucas Amostras:\n",
        "- Funciona bem mesmo com conjuntos de dados menores.\n",
        "- Robustez: Pode lidar bem com dados onde as classes s√£o separ√°veis linearmente.\n",
        "\n",
        "**Pontos Fracos**\n",
        "- Assun√ß√µes Restritivas: Assume que as classes t√™m a mesma matriz de covari√¢ncia e distribui√ß√µes gaussianas.\n",
        "- Sens√≠vel a Viola√ß√£o das Assun√ß√µes: Desempenho pode degradar-se se as assun√ß√µes n√£o forem atendidas.\n",
        "- Limita√ß√£o a Rela√ß√µes Lineares: N√£o captura rela√ß√µes n√£o lineares entre as features e as classes."
      ],
      "metadata": {
        "id": "OxJ3M2WDsuDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Linear Discriminant Analysis (LDA)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "y_pred_lda = lda.predict(X_test)\n",
        "print(\"\\nLinear Discriminant Analysis (LDA)\")\n",
        "print(\"Acur√°cia:\", accuracy_score(y_test, y_pred_lda))\n",
        "print(classification_report(y_test, y_pred_lda))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1z1hFP2qH9V",
        "outputId": "bd41a342-e94f-494b-f7df-7774da02f872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Linear Discriminant Analysis (LDA)\n",
            "Acur√°cia: 0.9532163742690059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.93        63\n",
            "           1       0.95      0.98      0.96       108\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.96      0.94      0.95       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n"
          ]
        }
      ]
    }
  ]
}